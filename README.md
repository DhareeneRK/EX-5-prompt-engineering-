
**🧪 EXPERIMENT 5: Comparative Analysis of Naïve Prompting vs Basic Prompting Using ChatGPT**

---

### 🧾 **RESULT**:

The prompt for the above-said problem **executed successfully**.

---

### 📊 **Deliverable: Comparative Table of Prompts & Responses**

| Scenario                 | Naïve Prompt                | ChatGPT Response (Naïve)                            | Basic Prompt                                                                              | ChatGPT Response (Basic)                                                        | Quality       | Accuracy      | Depth         |
| ------------------------ | --------------------------- | --------------------------------------------------- | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- | ------------- | ------------- | ------------- |
| 1. Creative Story        | “Tell me a story.”          | A short generic story about a dog and a boy.        | “Write a 300-word fantasy story about a brave girl who saves her village from a dragon.”  | A vivid and detailed fantasy tale with structure and character development.     | Basic > Naïve | Basic > Naïve | Basic > Naïve |
| 2. Factual Q\&A          | “Tell me about Mars.”       | General facts about Mars, inconsistent detail.      | “List five key facts about Mars’ atmosphere, moons, and exploration missions.”            | Concise and factual list with relevant data.                                    | Basic > Naïve | Basic > Naïve | Basic > Naïve |
| 3. Summarization         | “Summarize photosynthesis.” | Vague and overly simplified.                        | “Summarize the process of photosynthesis in 3-4 lines for a 10th-grade science textbook.” | Targeted, accurate summary appropriate for the level.                           | Basic > Naïve | Basic > Naïve | Basic > Naïve |
| 4. Advice/Recommendation | “Give me some advice.”      | Generic life advice (e.g., “be kind,” “work hard”). | “Give 3 tips for college students to stay productive during exams, with examples.”        | Specific, actionable tips with real-life context.                               | Basic > Naïve | Basic > Naïve | Basic > Naïve |
| 5. Technical Concept     | “Explain AI.”               | Very high-level and ambiguous.                      | “Explain AI in simple terms to a 12-year-old with examples of everyday use.”              | Clear, kid-friendly explanation with examples like Alexa and self-driving cars. | Basic > Naïve | Basic > Naïve | Basic > Naïve |

---

### 📈 **Analysis**

* **Prompt clarity** **greatly** improves the output across all categories—better structured, more relevant, and tailored to the task.
* **Naïve prompts** yield **generic, shallow, or vague** responses.
* **Basic prompts** provide **more targeted, informative, and refined** content.
* There were **no scenarios** where naïve prompts performed equally well as basic ones.

---

### 🧠 **Summary of Findings**

* **Basic prompting consistently outperforms naïve prompting** in all scenarios.
* **High-quality responses require clarity, context, and constraints.**
* **Prompt engineering is essential** for extracting specific, usable information from ChatGPT.
* For optimal results:
  ➤ Define the purpose clearly.
  ➤ Specify length, tone, audience, or format.
  ➤ Provide context or examples if needed.

---
